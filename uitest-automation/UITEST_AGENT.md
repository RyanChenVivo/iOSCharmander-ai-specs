# UITest Failure Analysis Toolkit

> **Command:** `/analyze-uitest [action]`

## Overview

When CI UITests fail, this toolkit provides a systematic approach to analyze and handle failures.

**Design Philosophy: Toolkit, Not Pipeline**
- Not every phase is required
- Choose appropriate tools based on the situation
- Phase 1 is the decision center; others are optional tools

---

## Workflows

### Phase 1: Triage - Required Entry Point

**Purpose:** Initial analysis, grouping, and recommendations

**Execute:** `/analyze-uitest` (automatically runs Phase 1)

**Process:**
1. Download test data (JSON files, lightweight)
2. Analyze failed tests
3. Group and categorize (Environment/Service/Timing/Bug)
4. Consult existing knowledge (patterns.md, observations/, external-dependencies.md)
5. Provide recommended path

**Output:** Verbal report + next step recommendations

â†’ See `workflows/triage.md` for details

---

### Phase 2: Investigate - Optional Tool

**When to Use:**
- â“ Root cause unclear
- ğŸ–¼ï¸ Need visual confirmation (UI-related issues)
- ğŸ” Need more evidence to conclude

**Execute:** `/analyze-uitest investigate`

**Process:**
1. Download screenshots and diagnostics (larger files)
2. Visual analysis of UI state
3. Compare expected vs actual screens
4. Confirm root cause

**Output:** Root cause analysis + updated recommendations

â†’ See `workflows/investigate.md` for details

---

### Phase 3: Report - Optional Tool

**When to Use:**
- ğŸ“‹ Need to report to management
- ğŸ“Š Need formal documentation
- ğŸ¤ Need team decision

**Execute:** `/analyze-uitest report`

**Process:**
1. Read analysis results from previous phases
2. Generate comprehensive Traditional Chinese report
3. Include: executive summary, detailed analysis, solution options, risk assessment, action plan

**Output:** `$HOME/Downloads/UITestAnalysis/latest/triage_report_YYYY-MM-DD.md`

â†’ See `workflows/report.md` for details

---

### Phase 4: Action - Optional Tool

**When to Use:**
- ğŸ“ Decide to observe and wait
- ğŸ”§ Decide to fix the issue
- ğŸ“š Record learnings to knowledge base

**Execute:** `/analyze-uitest observe` or `/analyze-uitest fix`

**Process:**
1. **observe**: Record to `observations/active.json`, track future occurrences
2. **fix**: Prompt to use `/openspec:proposal`, record learnings
3. **learn**: Add fix experience to `knowledge/patterns.md`

**Output:** Updated observations or prepared for OpenSpec creation

â†’ See `workflows/action.md` for details

---

## Decision Guide

### Quick Decision Tree

```
After Phase 1 completes:

â“ Any failures?
â”œâ”€ âŒ No â†’ Done âœ…
â””â”€ âœ… Yes â†“

â“ Root cause clear?
â”œâ”€ âœ… Clear and simple â†’ Phase 4 (observe)
â”œâ”€ â“ Unclear â†’ Phase 2 (investigate)
â””â”€ âœ… Clear but need report â†’ Phase 3 (report)

â“ Need to fix?
â”œâ”€ âœ… Yes â†’ Phase 4 (fix) â†’ /openspec:proposal
â””â”€ âŒ Observe only â†’ Phase 4 (observe)
```

### Common Scenarios

| Scenario | Recommended Flow | Notes |
|----------|------------------|-------|
| ğŸ‰ All tests pass | Phase 1 â†’ Done | Report success |
| ğŸŸ¢ Single simple error | Phase 1 â†’ Phase 4 | Record observation |
| ğŸŸ¡ UI-related error | Phase 1 â†’ Phase 2 â†’ Phase 3 | Need screenshots |
| ğŸ”´ Complex multi-group errors | Phase 1 â†’ Group handling | Different paths per group |
| ğŸ“‹ Need management decision | Phase 1 â†’ Phase 2 â†’ Phase 3 | Full investigation + report |

â†’ More detailed decision logic in `knowledge/decision-tree.md`

---

## External Service Change Decision Logic

When test failures are caused by external service changes, use this checklist to decide between creating an OpenSpec proposal immediately or observing first.

### âœ… Create OpenSpec Proposal Immediately

Create proposal when **ALL** of the following conditions are met:

- [ ] **Deterministic**: 100% reproducible, fails every time the test runs
- [ ] **Permanent**: External service change is intentional and published (not a temporary issue)
- [ ] **Programmable**: We can adapt our test code to handle the new behavior
- [ ] **Solution known**: Clear path exists to fix the test

**Example: Microsoft adds passkey dialog (2025-12-03)**
- âœ… Deterministic: Dialog appears every time
- âœ… Permanent: Microsoft officially released this feature
- âœ… Programmable: Can add code to click "Ask later" button
- âœ… Solution known: `handlePasskeyDialogIfNeeded()` function
- **Action**: Created `fix-uitest-failures-2025-12-03` proposal âœ“

### ğŸ”„ Observe First (1-2 days)

Observe first when **ANY** of the following conditions are met:

- [ ] **Uncertain**: Not clear if the change is permanent or temporary
- [ ] **First occurrence**: No historical pattern or previous record
- [ ] **Non-programmable**: Code cannot change external behavior (e.g., IP block, account lock, service outage)
- [ ] **Requires human intervention**: Need to contact IT/service provider/account admin
- [ ] **May auto-recover**: Security alerts, temporary degradation, backend slowness

**Example: Microsoft blocks CI IP (2025-12-10)**
- âœ… Uncertain: Could be temporary security flag
- âœ… First occurrence: First time seeing this specific block
- âœ… Non-programmable: Cannot bypass security blocking with code
- âœ… Requires human intervention: Need to check Azure AD logs and contact IT
- âœ… May auto-recover: Security systems often auto-unblock after investigation
- **Action**: Add to `observations/active.json`, observe until 2025-12-12 âœ“

### ğŸ“Š After Observation Period

If test still fails after observation period expires:

1. **Review observation history** from `observations/active.json`
2. **Analyze failure pattern**: Consistent (every time) vs intermittent (sometimes)
3. **Create OpenSpec proposal with context**:
   - Mention observation period in proposal (e.g., "Observed 2025-12-10 to 2025-12-12, failed consistently")
   - Include failure rate and pattern
   - Reference screenshots and error messages from triage reports
   - Document attempted mitigations or investigations
4. **Update external-dependencies.md** with the new behavior pattern

### ğŸ¯ Pattern Recognition

| Failure Type | Deterministic? | Programmable? | Action |
|--------------|----------------|---------------|--------|
| New UI element appears | âœ… Yes | âœ… Yes | Proposal |
| API endpoint changed | âœ… Yes | âœ… Yes | Proposal |
| Security/IP blocking | âŒ Uncertain | âŒ No | Observe |
| Account locked | âŒ Uncertain | âŒ No | Observe |
| Backend slow (timing) | âŒ Intermittent | âš ï¸ Maybe | Observe |
| Service outage | âŒ Temporary | âŒ No | Observe |

---

## Knowledge Base

### `knowledge/patterns.md` - Failure Pattern Library

**Purpose:** Record known failure patterns to improve decision consistency

**Contents:**
- Identification triggers (test name, error message)
- Diagnostic decisions (investigate/observe/report)
- Related fixes (archive/ links)

**Maintenance:**
- Manual editing (Markdown format)
- Prompted during Phase 4
- Accumulated over time

### `knowledge/decision-tree.md` - Decision Logic

**Purpose:** Help understand what to do in which situation

### `observations/` - Observation Tracking

**Purpose:** Track temporary issues under observation

**Files:**
- `active.json` - Currently observing (2-day expiration)
- `resolved.json` - Resolved/expired (30-day retention)

---

## Usage Examples

### Example 1: No Failures
```
User: /analyze-uitest
AI: [Phase 1] 120/120 tests passed âœ… No further action needed.
```

### Example 2: Simple Error
```
User: /analyze-uitest
AI: [Phase 1]
    Found 1 failure: NetworkTimeoutTest
    Error: Network timeout
    Category: Environment (transient)
    Recommendation: observe

User: /analyze-uitest observe
AI: [Phase 4] Recorded to observations/active.json
```

### Example 3: Investigation Needed (Today's Case)
```
User: /analyze-uitest
AI: [Phase 1]
    Found 8 failures in 3 groups:
    Group 1 (SSO, 3 tests) - ğŸ”´ Needs investigation
    Group 2 (Message, 4 tests) - ğŸŸ¡ Recommend observe
    Group 3 (License, 1 test) - ğŸŸ¢ Recommend observe

    Recommendation: investigate SSO group first

User: /analyze-uitest investigate
AI: [Phase 2]
    [Downloading screenshots...]
    Screenshot confirms: Microsoft blocking login
    Recommendation: generate report

User: /analyze-uitest report
AI: [Phase 3]
    Generated: triage_report_2025-12-10.md
```

---

## Advanced Features

<!-- ğŸ”® FUTURE ENHANCEMENT -->
### Semi-Automated Learning (Future)

**Feature:** Automatically extract patterns from OpenSpec archives

**Command:** `/analyze-uitest:learn [archive-name]`

**When:** After fix is completed and archived

**Purpose:**
- Auto-analyze proposal to find patterns
- Generate pattern draft
- Ask if should add to knowledge/patterns.md

**Status:** ğŸš§ To be implemented

---

## Documentation Index

- **workflows/**
  - `triage.md` - Phase 1 detailed process
  - `investigate.md` - Phase 2 detailed process
  - `report.md` - Phase 3 detailed process
  - `action.md` - Phase 4 detailed process

- **knowledge/** (AI diagnostic knowledge)
  - `patterns.md` - Failure pattern library
  - `decision-tree.md` - Decision logic
  - `external-dependencies.md` - Known external service issues
  - `timing-guidelines.md` - Timeout and wait strategies

- **reference/** (Test implementation reference)
  - `test-data.md` - Test data requirements
  - `ui-identifiers.md` - UI element accessibility IDs

- **observations/**
  - `active.json` - Current observations
  - `resolved.json` - Resolved observations

---

**Ready?** Run `/analyze-uitest` to start analyzing!
